#定义组件
a1.sources=r1
a1.channels=c1
a1.sinks=k1

#配置source1
a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
#每批次拉取的数据大小
a1.sources.r1.batchSize = 5000
#每批次拉取的周期
a1.sources.r1.batchDurationMillis = 2000
a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sources.r1.kafka.topics=topic_log
# 自定义拦截器(处理header)
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = com.zhou.gmail.flume.interceptor.TimestampInterceptor$Builder

#配置channel
a1.channels.c1.type = file
#备份内存中索引数据的磁盘路径
a1.channels.c1.checkpointDir = /opt/module/flume-1.9.0/checkpoint/behavior1
#存放channel中数据的磁盘路径, 在不同的磁盘上使用多个目录可以提高文件通道的性能
a1.channels.c1.dataDirs = /opt/module/flume-1.9.0/data/behavior1
#索引数据的二次备份, ，默认也是关闭
a1.channels.c1.useDualCheckpoints = false
#单个文件的最大大小
a1.channels.c1.maxFileSize = 2146435071
#channel通道的最大容量
a1.channels.c1.capacity = 1000000
#若channel数据拥挤, source传输数据将有等待时间(单位是秒), 若超过该时间, 数据会回滚
a1.channels.c1.keep-alive = 6

#配置sink
a1.sinks.k1.type = hdfs
#按天统计
a1.sinks.k1.hdfs.path = /origin_data/gmall/log/topic_log/%Y-%m-%d
#落盘文件前缀
a1.sinks.k1.hdfs.filePrefix = log
#默认也为false, 设置为true则搭配.roundValue和.roundUnit使用(详情看官网)
a1.sinks.k1.hdfs.round = false

#为解决hdfs中小文件过多, 设置以下3个参数
#滚动当前文件前等待的秒数, 若未达到hdfs文件中大小为128M, 则应该测试得到该值大小
a1.sinks.k1.hdfs.rollInterval = 10
#触发滚动的文件大小, 设置为128MB, 对应hdfs中块大小, 
a1.sinks.k1.hdfs.rollSize = 134217728
#文件滚动之前写入文件的event数量, 因为每个event大小可能不一样. 且可能差距过大, 无法保证最后hdfs文件的大小为128M, 所以设置为0, 即为取消 
a1.sinks.k1.hdfs.rollCount = 0

#控制输出文件类型
a1.sinks.k1.hdfs.fileType = CompressedStream
a1.sinks.k1.hdfs.codeC = gzip

#组装 
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

